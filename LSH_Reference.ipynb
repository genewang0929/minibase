{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = input(\"Please enter the number of layers: \")\n",
    "h = input(\"Please enter the number of hashes per layer: \")\n",
    "t = input(\"Please enter the number of similar videos: \")\n",
    "queryVideo = input(\"Enter the query video id: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TASK 3**\n",
    "\n",
    "**Part A:**\n",
    "Implement a Locality Sensitive Hashing (LSH) tool for Euclidean distance\n",
    "\n",
    "INPUT:\n",
    "* L = number of layers\n",
    "* h = number of hashes per layer\n",
    "* set of vectors (all target and non-target videos for a visual model (256 dimensions))\n",
    "\n",
    "OUPUT:\n",
    "* In-memory index structure containing the given set of vectors\n",
    "\n",
    "***\n",
    "\n",
    "**Part B:**\n",
    "Implement a similar video search tool using the index\n",
    "structure storing all target and non-target videos for a visual model\n",
    "of your choice.\n",
    "\n",
    "INPUT:\n",
    "* v = videoID\n",
    "* t = number of similar videos\n",
    "\n",
    "OUPUT:\n",
    "* list of videos in order of decreasing order of similarity\n",
    "* thumbnails of the most similar t videos\n",
    "* number of unique and overall video candidates considered during the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change random to set of vectors (all target and non-target videos for a visual model (256 dimensions))\n",
    "\n",
    "# Global variables for LSH\n",
    "layers = []\n",
    "buckets = []\n",
    "\n",
    "# Initialize LSH structure with L layers and h hash functions per layer.\n",
    "def initialize_lsh(L, h):\n",
    "\n",
    "    global layers, buckets\n",
    "    layers = [[np.random.randn(256) for _ in range(h)] for _ in range(L)]\n",
    "    buckets = [defaultdict(list) for _ in range(L)]\n",
    "\n",
    "# Hash a vector using a set of hyperplanes.\n",
    "def hash_vector(vector, hyperplanes):\n",
    "\n",
    "    return tuple(int(np.dot(vector, plane) >= 0) for plane in hyperplanes)\n",
    "\n",
    "# Add a vector to the LSH structure.\n",
    "def add_vector_to_lsh(vector, vector_id):\n",
    "\n",
    "    for i, hyperplanes in enumerate(layers):\n",
    "        hash_value = hash_vector(vector, hyperplanes)\n",
    "        buckets[i][hash_value].append(vector_id)\n",
    "\n",
    "# Build the LSH index for a set of vectors.\n",
    "def build_lsh_index(vectors):\n",
    "\n",
    "    for vector_id, vector in enumerate(vectors):\n",
    "        add_vector_to_lsh(vector, vector_id)\n",
    "\n",
    "# Query the LSH structure for similar vectors.\n",
    "def query_lsh(vector):\n",
    "\n",
    "    candidates = set()\n",
    "    for i, hyperplanes in enumerate(layers):\n",
    "        hash_value = hash_vector(vector, hyperplanes)\n",
    "        candidates.update(buckets[i][hash_value])\n",
    "    return list(candidates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change distance with similarity score\n",
    "# TODO: add thumbnails\n",
    "\n",
    "# Search the LSH index for the most similar videos to a query video ID.\n",
    "def video_search_lsh(query_video_id, vectors, t):\n",
    "\n",
    "    # Retrieve the query vector\n",
    "    query_vector = vectors[query_video_id]\n",
    "    \n",
    "    # Get candidate vector IDs using LSH\n",
    "    candidate_ids = query_lsh(query_vector)\n",
    "    \n",
    "    # Compute Euclidean distances between the query vector and the candidates\n",
    "    similarities = []\n",
    "    for vector_id in candidate_ids:\n",
    "        distance = np.linalg.norm(query_vector - vectors[vector_id])\n",
    "        similarities.append((vector_id, distance))\n",
    "    \n",
    "    # Sort by distance (ascending)\n",
    "    sorted_candidates = sorted(similarities, key=lambda x: x[1])\n",
    "    \n",
    "    # Get the top t most similar videos\n",
    "    top_t = sorted_candidates[:t]\n",
    "\n",
    "    # Statistics\n",
    "    unique_candidates = len(set(candidate_ids))  # Unique candidates retrieved\n",
    "    overall_candidates = len(candidate_ids)  # Total candidates retrieved\n",
    "\n",
    "    return top_t, unique_candidates, overall_candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 similar videos to video ID 0:\n",
      "1: Video ID 0, Distance: 0.0000\n",
      "2: Video ID 88, Distance: 20.7514\n",
      "3: Video ID 40, Distance: 20.8395\n",
      "4: Video ID 94, Distance: 21.0309\n",
      "5: Video ID 98, Distance: 21.1167\n",
      "Unique candidates: 23, Overall candidates: 23\n"
     ]
    }
   ],
   "source": [
    "L = 5  # Number of layers\n",
    "h = 4  # Number of hash functions per layer\n",
    "num_vectors = 100  # Number of vectors to index\n",
    "t = 5  # Number of most similar videos to retrieve\n",
    "\n",
    "# Generate random vectors\n",
    "np.random.seed(42)\n",
    "vectors = np.random.randn(num_vectors, 256)\n",
    "\n",
    "# Initialize LSH\n",
    "initialize_lsh(L, h, 256)\n",
    "\n",
    "# Build the index\n",
    "build_lsh_index(vectors)\n",
    "\n",
    "# Query for the first vector\n",
    "query_video_id = 0  # Video ID to query\n",
    "results, unique_count, overall_count = video_search_lsh(query_video_id, vectors, t)\n",
    "\n",
    "print(f\"Top {t} similar videos to video ID {query_video_id}:\")\n",
    "for rank, (video_id, distance) in enumerate(results, start=1):\n",
    "    print(f\"{rank}: Video ID {video_id}, Distance: {distance:.4f}\")\n",
    "print(f\"Unique candidates: {unique_count}, Overall candidates: {overall_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
